# Part 2 - Vectorisons quelques pages avec Temporal IO

* ‚è∞ Dur√©e : 30min
* üéØ Objectifs :
  * D√©couvrir Temporal et son backoffice
  * D√©couverte du mod√®le de donn√©es utilis√© pendant le workshop
  * Coder et lancer l'activit√© d'indexation sur des pages web pr√©-t√©l√©charg√©es

## D√©couverte de Temporal IO

Temporal IO est une plateforme open-source de gestion de workflows distribu√©s, con√ßue pour rendre les syst√®mes complexes
fiables, r√©silients et faciles √† raisonner. Elle permet d‚Äôorchestrer des t√¢ches longues, critiques ou d√©pendantes les
unes des autres (paiements, traitements de donn√©es, automatisations m√©tiers, pipelines IA, etc.) tout en garantissant 
la reprise automatique en cas d‚Äôerreur, de crash, de d√©ploiement, ou m√™me de red√©marrage de machine. Avec Temporal, 
chaque √©tape d‚Äôun workflow est durablement enregistr√©e dans un ‚Äúhistory log‚Äù, ce qui √©limine la gestion manuelle des 
√©tats, des timeouts, des retry policies, du backoff, ou des verrous distribu√©s.

Concr√®tement, Temporal s√©pare la logique m√©tier (les workflows) et l‚Äôex√©cution des actions externes (les activities), 
tout en offrant des primitives puissantes : timers fiables, retours asynchrones, signaux, queries, sous-workflows, et 
une coh√©rence garantie. Cela permet d‚Äô√©crire du code simple, comme une fonction normale, qui devient automatiquement 
r√©sistant aux pannes et hautement scalable gr√¢ce au moteur de Temporal. C‚Äôest aujourd‚Äôhui utilis√© par des entreprises 
comme Datadog, OVH, Stripe, Snap ou Descript pour orchestrer des milliers √† des millions d‚Äôop√©rations de mani√®re s√ªre et 
d√©terministe.

### Pourquoi le choix de Temporal IO

Les activit√©s de collecte de donn√©es sont des activit√©s longues (un web crawling peut s‚Äô√©taler sur plusieurs heures),
pour d√©couvrir (crawling) et t√©l√©charger (scraping) des milliers de pages web.

Le nettoyage des documents collect√©s et leur conversion sont √©galement des t√¢ches longues, qui peuvent parfois n√©cessiter
des ressources GPU (mod√®les de d√©tection de layout, OCR‚Ä¶) et doivent pouvoir reprendre
sans tout rejouer.

Enfin, l‚Äôindexation / vectorisation des documents peut elle aussi, en fonction des mod√®les utilis√©s et des ressources
disponibles, s‚Äô√©taler sur plusieurs heures, voire des jours d‚Äôex√©cution.

### Mod√®le de donn√©es qui serait utilis√©

Dans ce workshop, nous allons travailler avec le mod√®le de donn√©es suivant, il est d√©j√† impl√©ment√© :
* En python au travers d'objets PyDantic disponible ICI TODO
* En Typescript (nous le verrons par la suite)

En bref :
* **Source** : repr√©sente chaque page web tout au long de son traitement
  - source.medata : contien des cl√© valeur qui arriveront en base vectorielle, notamment la metdata.title qui contien le titre de la page.
* **IngestionWorkflowInput** : repr√©sente les donn√©es d'entr√©e de notre workflow

```mermaid
---
title: Mod√®le de donn√©es - Workflow d'ingestion
---
classDiagram
    class Source{
        +String uri
        +MimeTypesEnum mime_type
        +StageEnum current_stage
        +String error
        +String raw_file_path
        +String converted_md_path
        +String chunking_file_path
        +Dict metadata
    }
    Source "1" --o "1" MimeTypesEnum : as format
    Source "1" --o "1" StageEnum : is at current state
    Source "1" --o "1" StatusEnum : as current status
    
    class StageEnum{
    <<enumeration>>
        CRAWLING
        SCRAPING
        CONVERTION
        CHUNKING
        INDEXING
    }
    
    class MimeTypesEnum{
        TEXT_HTML
        UNSUPORTED_MIME_TYPE
    }
    
    class StageConfiguration{
        +int bulk_size
    }
    
    class IndexingStageConfiguration{
        +String collection_name
        +String database_uri
        +String openai_embedding_model
    }
    
    class IngestionWorkflowInput{
        +List~Source~ sources
        +IndexingStageConfiguration indexing_config
    }
    IngestionWorkflowInput "1" --o "1" IndexingStageConfiguration: indexing_config
```

Ce mod√®le est d√©crit en json sch√©mas dans *ingestion-workflow-model-schemas*, nous utilisons du json sch√©ma pour 
le d√©cliner en Pydantic et en mod√®le TypeScript, puisque Temporal nous permet d'impl√©menter des activit√©s dans plusieurs
langages, nous verrons ceci en partie 4.

*Vous n'aurez pas √† toucher aux sch√©mas, si besoin vous avez des Run Config PyCharm / Intelij permettant de les re-g√©n√©rer
en python et typescript.*

### Notre premier workflow

Il est important de retenir qu'un workflow ne peut effectuer que des actions d√©terministes, il ne peut par exemple pas
aller appeler une API, cr√©er un dossier ou fichier, lire des variables d'environnement.

C'est un concept tr√®s important dans Temporal ce sont les activit√©s qui effectu√©es ces op√©rations. Ceci permet √† Temporal
de m√©moriser les entr√©e / sortie de chaque ex√©cution d'activit√©s (dans l'Event History du Workflow) et en cas de reprise 
d'un workflow pour une m√™me donn√©es d'entr√©e d'une activit√© retourner la valeur de retour qu'il a enregistr√© et ainsi ne
pas tout r√©-ex√©cuter.

TODO Sch√©ma du workflow
TODO explication des entr√©es sortie de l'activit√© de print et indexing.
TODO expliquer les namespace + task_queue.

On va commencer par aller droit au but de mani√®re tr√®s simple mettre en base le contenu brute des 2 pages d'article
pr√©-t√©l√©charg√©e pr√©sentes dans *ingestion-workflow-py/ressources/brest_transport_pre_scraped_pages/*.

Le workflow et d√©j√† initialis√© ici *ingestion-workflow-py/src/ingestion_workflow/workflows/ingestion_workflow.py*.
Vous pouvez aller regarder le code comment√©.

Pour l'instant il ne fait que print la liste des sources avec une activit√© d√©j√† initialis√©e dans `ingestion-workflow-py/src/ingestion_workflow/activities/print_source_activity.py`.
Vous pourrez vous en inspirer pour cr√©er l'activit√© d'indexation.

### Notre premier worker

#### Namespace et Task Queue

Les code des activit√©s et des workflow est ex√©cut√© par ce qu'on appel des [Worker Temporal](https://docs.temporal.io/workers).
Ces workers √©coutent sur des files d'attentes, task queue pour r√©cup√©rer des t√¢ches (ex√©cution d'activit√© ou de workflow),
ici on utilisera une task queue appel√©e `PY_WORKER_TASK_QUEUE`.
Ces tasks queues sont elles m√™me rang√©es au sein de namespaces, par d√©faut la stack docker compose a cr√©√© le namespace `workshop-ingestion`. 

TODO Sch√©ma ??

Cas d'usages de task queues diff√©rentes :
* Si vous avez des activit√©s n√©cessitant une GPU, vous aurez 
un worker d√©ployer sur une machine ayant une carte graphique et √©coutant sur une Task Queue sp√©cifique.
* Des workers dans diff√©rents languages, vous allez pouvoir cr√©er une task queue par langage.
* Si vous souhaitez avoir des worker ayant des droits d'acc√®s diff√©rents pour bien isoler les ex√©cutions,
par exemple un worker ayant acc√®s √† internet pour le crawling scrapping de sites publiques un autre interne pour vos intranet.


### Cr√©ons et lan√ßons Main Worker

Ouvrez `ingestion-workflow-py/src/ingestion_workflow/worker/main_worker.py`, nous allons compl√©ter ce script.

D'abord il vous faut cr√©er un client Temporal :
* Temporal dialogue en GRCP sur localhost:7233
* Nous allons travailler sur le namespace `workshop-ingestion`

```python
from temporalio.client import Client

client: Client = await Client.connect("localhost:7233", namespace="workshop-ingestion")
```

Une fois le client cr√©√© vous pouvez cr√©er un Worker Temporal :
* il √©coute sur la file d'attente / task queue `PY_WORKER_TASK_QUEUE`
* il est capable d'ex√©cuter le code de notre workflow la classe `IngestionWorkflow`
* il est capable d'ex√©cuter le code de notre activit√© d'exemple qui print des sources, la fonction `print_source_activity`

Vous pouvez le cr√©er avec le code suivant :

```python
from temporalio.worker import Worker
from avelbot_ingestion.workflows.ingestion_workflow import IngestionWorkflow
from avelbot_ingestion.activities.print_source_activity import print_source_activity
from avelbot_ingestion.worker.utils import build_sandbox_worker_runner_vscode_debug_compatible

worker: Worker = Worker(
  client,
  task_queue="PY_WORKER_TASK_QUEUE",  # Nom de la file sur laquelle √©coute le worker
  workflows=[IngestionWorkflow],  # Code des workflow qu'est capable d'ex√©cuter le worker
  activities=[print_source_activity],  # Liste des activit√©s qu'est capable d'ex√©cuter le worker
  debug_mode=True, # Utile en dev
  workflow_runner=build_sandbox_worker_runner_vscode_debug_compatible() # Used to prevent VS Code issue
)
```

> build_sandbox_worker_runner_vscode_debug_compatible permet de cr√©er un context du worker compatible
> avec le debugger de VS Code qui inject la lib _pydevd_bundle que temporal doit laisser passer.

<details>
  <summary>Code complet de `main_worker.py`</summary>

```python
import asyncio

from temporalio.client import Client
from temporalio.worker import Worker

from avelbot_ingestion.activities.print_source_activity import print_source_activity
from avelbot_ingestion.helpers.logging_config import get_app_logger, configure_logging
from avelbot_ingestion.worker.utils import build_sandbox_worker_runner_vscode_debug_compatible
from avelbot_ingestion.workflows.ingestion_workflow import IngestionWorkflow

from dotenv import load_dotenv, find_dotenv

load_dotenv(find_dotenv())
logger = get_app_logger(__name__)

async def main() -> None:
    logger.info("Starting main python worker ...")

    # COMPLETER ICI - START
    # - Initialiser le client temporal
    # - Cr√©er le Worker
    # - D√©marrer le worker
    client: Client = await Client.connect("localhost:7233", namespace="workshop-ingestion")
    worker: Worker = Worker(
        client,
        task_queue="PY_WORKER_TASK_QUEUE", # Nom de la file sur laquelle √©coute le worker
        workflows=[IngestionWorkflow], # Code des workflow qu'est capable d'ex√©cuter le worker
        activities=[print_source_activity], # Liste des activit√©s qu'est capable d'ex√©cuter le worker
        debug_mode=True,
        workflow_runner=build_sandbox_worker_runner_vscode_debug_compatible() # Used to prevent VS Code issue
    )
    await worker.run()
    # COMPLETER ICI - END

if __name__ == "__main__":
    configure_logging(caller="main_worker") # Configurer un logger avec un peu de couleur
    asyncio.run(main())
```
</details>

Pour lancer le worker **utilisez de pr√©f√©rence** la run configuration PyCharm ou VS Code **Main Worker** ou en ligne de commande :
```bash
cd $(git rev-parse --show-toplevel)/avelbot-ingestion-py/src/avelbot_ingestion/worker
python main_worker.py
```

### Lan√ßons notre premier workflow

### Input d'entr√©e

Les donn√©es d'entr√©e du workflow correspondent au format `IngestionWorkflowInput`, vous trouverez le ficher comment√©
au format yaml ici [part2-vect_pages_with_temporal.yml](../avelbot-ingestion-py/ressources/workflow_inputs/part2-vect_pages_with_temporal.yml).

Temporal UI ne supporte que le format json, les fichiers on donc √©taient convertis en json : 
`yq -o=json eval part2-vect_pages_with_temporal.yml > part2-vect_pages_with_temporal.json`)

### Trigger le workflow via Temporal UI

* Allez sur le dashboard Temporal : http://localhost:8233/
* S√©lectionner le bon namespace `workshop-ingestion` :
![select workshop-ingestion namespace](./images/part2-select-namespace.png)
* Cliquer sur le bouton "Start Workflow" :
  * Workflow ID : Random UUID
  * Task Queue : `PY_WORKER_TASK_QUEUE`
  * Workflow Type, nom mis sur le d√©corateur de la class python du workflow : `INGESTION_WORKFLOW`
  * Input, il s'agit des donn√©es d'entr√©e, ici `part2-vect_pages_with_temporal.json`.
  * Cliquer sur **Start Workflow**

Vous devriez avoir les param√®tres suivants :
![](./images/part2-trigger_workflow_temporal-ui.png)


### Trigger le workflow via une run configuration VS Code ou PyCharm


### En CLI

Il existe un petit script python permettant via le SDK Temporal de trigger un workflow, avec les m√™mes param√®tres que sur le backoffice (n'h√©sitez pas √† aller le voir) :
```bash
cd $(git rev-parse --show-toplevel)/avelbot-ingestion-py/ressources/workflow_inputs
python ../../src/avelbot_ingestion/runners/trigger_ingestion_workflow.py --workflow-input-yaml=part2-vect_pages_with_temporal.yml
```

#### Via PyCharm

Avec PyCharm vous risquez d'avoir l'erreur suivante au niveau du worker :
```
[ERROR] temporalio.worker._workflow_instance:2711 - Exception in callback <Task pending name='query: __temporal_workflow_metadata (workflow: IngestionWorkflow, id: 94f5bdf3-f7f2-4037-b905-d4f0d23276a0, run: 019ab101-8bfc-7ae5-af76-f85c733c5e47)' coro=<_WorkflowInstanceImpl._apply_query_workflow.<locals>.run_query() running at workshop-temporal-genai-ingestion/.venv/lib/python3.13/site-packages/temporalio/worker/_workflow_instance.py:712> cb=[set.remove()]>()
handle: <Handle <Task pending name='query: __temporal_workflow_metadata (workflow: IngestionWorkflow, id: 94f5bdf3-f7f2-4037-b905-d4f0d23276a0, run: 019ab101-8bfc-7ae5-af76-f85c733c5e47)' coro=<_WorkflowInstanceImpl._apply_query_workflow.<locals>.run_query() running at workshop-temporal-genai-ingestion/.venv/lib/python3.13/site-packages/temporalio/worker/_workflow_instance.py:712> cb=[set.remove()]>()>
```

Ceci est li√© √† un [bug entre le debugger de PyCharm et AsyncIO](https://youtrack.jetbrains.com/issue/PY-64542),
pour le r√©gler :
* Help > Find Actions > Registry (+ Entrer)
* CTRL + F, chercher **python.debug.asyncio.repl**
* D√©cocher, relancer PyCharm

Vous pouvez ensuite lancer le workflow via les 2 run configuration suivantes :
* D√©marrage du worker avec la configuration **Main Worker**
* Trigger du workflow avec la configuration Trigger Workflow > Part 2 - Indexing pre-fetch pages

#### VS Code et debug

Sur VS Code lancer la configuration `[üêç] Trigger - Part 2 - Indexing pages`.


