# Part 2 - Vectorisons quelques pages avec Temporal IO

* ‚è∞ Dur√©e : 30min
* üéØ Objectifs :
  * D√©couvrir Temporal et son backoffice
  * D√©couverte du mod√®le de donn√©es utilis√© pendant le workshop
  * Coder et lancer l'activit√© d'indexation sur des pages web pr√©-t√©l√©charg√©es

<!-- TOC -->
* [Part 2 - Vectorisons quelques pages avec Temporal IO](#part-2---vectorisons-quelques-pages-avec-temporal-io)
  * [D√©couverte de Temporal IO](#d√©couverte-de-temporal-io)
    * [Pourquoi le choix de Temporal IO](#pourquoi-le-choix-de-temporal-io)
    * [Mod√®le de donn√©es qui serait utilis√©](#mod√®le-de-donn√©es-qui-serait-utilis√©)
    * [Notre premier workflow](#notre-premier-workflow)
    * [Notre premier worker](#notre-premier-worker)
      * [Namespace et Task Queue](#namespace-et-task-queue)
    * [Cr√©ons et lan√ßons Main Worker](#cr√©ons-et-lan√ßons-main-worker)
    * [Lan√ßons notre premier workflow](#lan√ßons-notre-premier-workflow)
    * [Input d'entr√©e](#input-dentr√©e)
    * [Trigger le workflow via Temporal UI](#trigger-le-workflow-via-temporal-ui)
    * [Trigger le workflow via une run configuration VS Code ou PyCharm](#trigger-le-workflow-via-une-run-configuration-vs-code-ou-pycharm)
    * [En CLI](#en-cli)
      * [Via PyCharm](#via-pycharm)
      * [VS Code et debug](#vs-code-et-debug)
  * [Indexons des pages pr√©-t√©l√©charg√©es](#indexons-des-pages-pr√©-t√©l√©charg√©es)
    * [Compl√©ter l'activit√© index_source_no_chunk_activity](#compl√©ter-lactivit√©-index_source_no_chunk_activity)
    * [Appeler l'activit√©e depuis le workflow](#appeler-lactivit√©e-depuis-le-workflow)
    * [Indexons les pages](#indexons-les-pages)
    * [V√©rifions sur AvelBot](#v√©rifions-sur-avelbot)
<!-- TOC -->

## D√©couverte de Temporal IO

Temporal IO est une plateforme open-source de gestion de workflows distribu√©s, con√ßue pour rendre les syst√®mes complexes
fiables, r√©silients et faciles √† raisonner. Elle permet d‚Äôorchestrer des t√¢ches longues, critiques ou d√©pendantes les
unes des autres (paiements, traitements de donn√©es, automatisations m√©tiers, pipelines IA, etc.) tout en garantissant 
la reprise automatique en cas d‚Äôerreur, de crash, de d√©ploiement, ou m√™me de red√©marrage de machine. Avec Temporal, 
chaque √©tape d‚Äôun workflow est durablement enregistr√©e dans un ‚Äúhistory log‚Äù, ce qui √©limine la gestion manuelle des 
√©tats, des timeouts, des retry policies, du backoff, ou des verrous distribu√©s.

Concr√®tement, Temporal s√©pare la logique m√©tier (les workflows) et l‚Äôex√©cution des actions externes (les activities), 
tout en offrant des primitives puissantes : timers fiables, retours asynchrones, signaux, queries, sous-workflows, et 
une coh√©rence garantie. Cela permet d‚Äô√©crire du code simple, comme une fonction normale, qui devient automatiquement 
r√©sistant aux pannes et hautement scalable gr√¢ce au moteur de Temporal. C‚Äôest aujourd‚Äôhui utilis√© par des entreprises 
comme Datadog, OVH, Stripe, Snap ou Descript pour orchestrer des milliers √† des millions d‚Äôop√©rations de mani√®re s√ªre et 
d√©terministe.

### Pourquoi le choix de Temporal IO

Les activit√©s de collecte de donn√©es sont des activit√©s longues (un web crawling peut s‚Äô√©taler sur plusieurs heures),
pour d√©couvrir (crawling) et t√©l√©charger (scraping) des milliers de pages web.

Le nettoyage des documents collect√©s et leur conversion sont √©galement des t√¢ches longues, qui peuvent parfois n√©cessiter
des ressources GPU (mod√®les de d√©tection de layout, OCR‚Ä¶) et doivent pouvoir reprendre
sans tout rejouer.

Enfin, l‚Äôindexation / vectorisation des documents peut elle aussi, en fonction des mod√®les utilis√©s et des ressources
disponibles, s‚Äô√©taler sur plusieurs heures, voire des jours d‚Äôex√©cution.

### Mod√®le de donn√©es qui serait utilis√©

Dans ce workshop, nous allons travailler avec le mod√®le de donn√©es suivant, il est d√©j√† impl√©ment√© :
* En python au travers d'objets PyDantic disponible ICI TODO
* En Typescript (nous le verrons par la suite)

En bref :
* **Source** : repr√©sente chaque page web tout au long de son traitement
  - source.medata : contien des cl√© valeur qui arriveront en base vectorielle, notamment la metdata.title qui contien le titre de la page.
* **IngestionWorkflowInput** : repr√©sente les donn√©es d'entr√©e de notre workflow

```mermaid
---
title: Mod√®le de donn√©es - Workflow d'ingestion
---
classDiagram
    class Source{
        +String uri
        +MimeTypesEnum mime_type
        +StageEnum current_stage
        +String error
        +String raw_file_path
        +String converted_md_path
        +String chunking_file_path
        +Dict metadata
    }
    Source "1" --o "1" MimeTypesEnum : as format
    Source "1" --o "1" StageEnum : is at current state
    Source "1" --o "1" StatusEnum : as current status
    
    class StageEnum{
    <<enumeration>>
        CRAWLING
        SCRAPING
        CONVERTION
        CHUNKING
        INDEXING
    }
    
    class MimeTypesEnum{
        TEXT_HTML
        UNSUPORTED_MIME_TYPE
    }
    
    class StageConfiguration{
        +int bulk_size
    }
    
    class IndexingStageConfiguration{
        +String collection_name
        +String database_uri
        +String openai_embedding_model
    }
    
    class IngestionWorkflowInput{
        +List~Source~ sources
        +IndexingStageConfiguration indexing_config
    }
    IngestionWorkflowInput "1" --o "1" IndexingStageConfiguration: indexing_config
```

Ce mod√®le est d√©crit en json sch√©mas dans *ingestion-workflow-model-schemas*, nous utilisons du json sch√©ma pour 
le d√©cliner en Pydantic et en mod√®le TypeScript, puisque Temporal nous permet d'impl√©menter des activit√©s dans plusieurs
langages, nous verrons ceci en partie 4.

*Vous n'aurez pas √† toucher aux sch√©mas, si besoin vous avez des Run Config PyCharm / Intelij permettant de les re-g√©n√©rer
en python et typescript.*

### Notre premier workflow

Il est important de retenir qu'un workflow ne peut effectuer que des actions d√©terministes, il ne peut par exemple pas
aller appeler une API, cr√©er un dossier ou fichier, lire des variables d'environnement.

C'est un concept tr√®s important dans Temporal ce sont les activit√©s qui effectu√©es ces op√©rations. Ceci permet √† Temporal
de m√©moriser les entr√©e / sortie de chaque ex√©cution d'activit√©s (dans l'Event History du Workflow) et en cas de reprise 
d'un workflow pour une m√™me donn√©es d'entr√©e d'une activit√© retourner la valeur de retour qu'il a enregistr√© et ainsi ne
pas tout r√©-ex√©cuter.

TODO Sch√©ma du workflow
TODO explication des entr√©es sortie de l'activit√© de print et indexing.
TODO expliquer les namespace + task_queue.

On va commencer par aller droit au but de mani√®re tr√®s simple mettre en base le contenu brute des 2 pages d'article
pr√©-t√©l√©charg√©e pr√©sentes dans *ingestion-workflow-py/ressources/brest_transport_pre_scraped_pages/*.

Le workflow et d√©j√† initialis√© ici *ingestion-workflow-py/src/ingestion_workflow/workflows/ingestion_workflow.py*.
Vous pouvez aller regarder le code comment√©.

Pour l'instant il ne fait que print la liste des sources avec une activit√© d√©j√† initialis√©e dans `ingestion-workflow-py/src/ingestion_workflow/activities/print_source_activity.py`.
Vous pourrez vous en inspirer pour cr√©er l'activit√© d'indexation.

### Notre premier worker

#### Namespace et Task Queue

Les code des activit√©s et des workflow est ex√©cut√© par ce qu'on appel des [Worker Temporal](https://docs.temporal.io/workers).
Ces workers √©coutent sur des files d'attentes, task queue pour r√©cup√©rer des t√¢ches (ex√©cution d'activit√© ou de workflow),
ici on utilisera une task queue appel√©e `PY_WORKER_TASK_QUEUE`.
Ces tasks queues sont elles m√™me rang√©es au sein de namespaces, par d√©faut la stack docker compose a cr√©√© le namespace `workshop-ingestion`. 

TODO Sch√©ma ??

Cas d'usages de task queues diff√©rentes :
* Si vous avez des activit√©s n√©cessitant une GPU, vous aurez 
un worker d√©ployer sur une machine ayant une carte graphique et √©coutant sur une Task Queue sp√©cifique.
* Des workers dans diff√©rents languages, vous allez pouvoir cr√©er une task queue par langage.
* Si vous souhaitez avoir des worker ayant des droits d'acc√®s diff√©rents pour bien isoler les ex√©cutions,
par exemple un worker ayant acc√®s √† internet pour le crawling scrapping de sites publiques un autre interne pour vos intranet.


### Cr√©ons et lan√ßons Main Worker

Ouvrez `ingestion-workflow-py/src/ingestion_workflow/worker/main_worker.py`, nous allons compl√©ter ce script.

D'abord il vous faut cr√©er un client Temporal :
* Temporal dialogue en GRCP sur localhost:7233
* Nous allons travailler sur le namespace `workshop-ingestion`

```python
from temporalio.client import Client

client: Client = await Client.connect("localhost:7233", namespace="workshop-ingestion")
```

Une fois le client cr√©√© vous pouvez cr√©er un Worker Temporal :
* il √©coute sur la file d'attente / task queue `PY_WORKER_TASK_QUEUE`
* il est capable d'ex√©cuter le code de notre workflow la classe `IngestionWorkflow`
* il est capable d'ex√©cuter le code de notre activit√© d'exemple qui print des sources, la fonction `print_source_activity`

Vous pouvez le cr√©er avec le code suivant :

```python
from temporalio.worker import Worker
from avelbot_ingestion.workflows.ingestion_workflow import IngestionWorkflow
from avelbot_ingestion.activities.print_source_activity import print_source_activity
from avelbot_ingestion.worker.utils import build_sandbox_worker_runner_vscode_debug_compatible

worker: Worker = Worker(
  client,
  task_queue="PY_WORKER_TASK_QUEUE",  # Nom de la file sur laquelle √©coute le worker
  workflows=[IngestionWorkflow],  # Code des workflow qu'est capable d'ex√©cuter le worker
  activities=[print_source_activity],  # Liste des activit√©s qu'est capable d'ex√©cuter le worker
  debug_mode=True, # Utile en dev
  workflow_runner=build_sandbox_worker_runner_vscode_debug_compatible() # Used to prevent VS Code issue
)
```

> build_sandbox_worker_runner_vscode_debug_compatible permet de cr√©er un context du worker compatible
> avec le debugger de VS Code qui inject la lib _pydevd_bundle que temporal doit laisser passer.

<details>
  <summary>Code complet de `main_worker.py`</summary>

```python
import asyncio

from temporalio.client import Client
from temporalio.worker import Worker

from avelbot_ingestion.activities.print_source_activity import print_source_activity
from avelbot_ingestion.helpers.logging_config import get_app_logger, configure_logging
from avelbot_ingestion.worker.utils import build_sandbox_worker_runner_vscode_debug_compatible
from avelbot_ingestion.workflows.ingestion_workflow import IngestionWorkflow

from dotenv import load_dotenv, find_dotenv

load_dotenv(find_dotenv())
logger = get_app_logger(__name__)

async def main() -> None:
    logger.info("Starting main python worker ...")

    # COMPLETER ICI - START
    # - Initialiser le client temporal
    # - Cr√©er le Worker
    # - D√©marrer le worker
    client: Client = await Client.connect("localhost:7233", namespace="workshop-ingestion")
    worker: Worker = Worker(
        client,
        task_queue="PY_WORKER_TASK_QUEUE", # Nom de la file sur laquelle √©coute le worker
        workflows=[IngestionWorkflow], # Code des workflow qu'est capable d'ex√©cuter le worker
        activities=[print_source_activity], # Liste des activit√©s qu'est capable d'ex√©cuter le worker
        debug_mode=True,
        workflow_runner=build_sandbox_worker_runner_vscode_debug_compatible() # Used to prevent VS Code issue
    )
    await worker.run()
    # COMPLETER ICI - END

if __name__ == "__main__":
    configure_logging(caller="main_worker") # Configurer un logger avec un peu de couleur
    asyncio.run(main())
```
</details>

Pour lancer le worker **utilisez de pr√©f√©rence** la run configuration PyCharm ou VS Code **Main Worker** ou en ligne de commande :
```bash
cd $(git rev-parse --show-toplevel)/avelbot-ingestion-py/src/avelbot_ingestion/worker
python main_worker.py
```

### Lan√ßons notre premier workflow

### Input d'entr√©e

Les donn√©es d'entr√©e du workflow correspondent au format `IngestionWorkflowInput`, vous trouverez le ficher comment√©
au format yaml ici [part2-vect_pages_with_temporal.yml](../avelbot-ingestion-py/ressources/workflow_inputs/part2-vect_pages_with_temporal.yml).

Temporal UI ne supporte que le format json, les fichiers on donc √©taient convertis en json : 
`yq -o=json eval part2-vect_pages_with_temporal.yml > part2-vect_pages_with_temporal.json`)

### Trigger le workflow via Temporal UI

* Allez sur le dashboard Temporal : http://localhost:8233/
* S√©lectionner le bon namespace `workshop-ingestion` :
![select workshop-ingestion namespace](./images/part2-select-namespace.png)
* Cliquer sur le bouton "Start Workflow" :
  * Workflow ID : Random UUID
  * Task Queue : `PY_WORKER_TASK_QUEUE`
  * Workflow Type, nom mis sur le d√©corateur de la class python du workflow : `INGESTION_WORKFLOW`
  * Input, il s'agit des donn√©es d'entr√©e, ici `part2-vect_pages_with_temporal.json`.
  * Cliquer sur **Start Workflow**

Vous devriez avoir les param√®tres suivants :
![](./images/part2-trigger_workflow_temporal-ui.png)


### Trigger le workflow via une run configuration VS Code ou PyCharm


### En CLI

Il existe un petit script python permettant via le SDK Temporal de trigger un workflow, avec les m√™mes param√®tres que sur le backoffice (n'h√©sitez pas √† aller le voir) :
```bash
cd $(git rev-parse --show-toplevel)/avelbot-ingestion-py/ressources/workflow_inputs
python ../../src/avelbot_ingestion/runners/trigger_ingestion_workflow.py --workflow-input-yaml=part2-vect_pages_with_temporal.yml
```

#### Via PyCharm

Avec PyCharm vous risquez d'avoir l'erreur suivante au niveau du worker :
```
[ERROR] temporalio.worker._workflow_instance:2711 - Exception in callback <Task pending name='query: __temporal_workflow_metadata (workflow: IngestionWorkflow, id: 94f5bdf3-f7f2-4037-b905-d4f0d23276a0, run: 019ab101-8bfc-7ae5-af76-f85c733c5e47)' coro=<_WorkflowInstanceImpl._apply_query_workflow.<locals>.run_query() running at workshop-temporal-genai-ingestion/.venv/lib/python3.13/site-packages/temporalio/worker/_workflow_instance.py:712> cb=[set.remove()]>()
handle: <Handle <Task pending name='query: __temporal_workflow_metadata (workflow: IngestionWorkflow, id: 94f5bdf3-f7f2-4037-b905-d4f0d23276a0, run: 019ab101-8bfc-7ae5-af76-f85c733c5e47)' coro=<_WorkflowInstanceImpl._apply_query_workflow.<locals>.run_query() running at workshop-temporal-genai-ingestion/.venv/lib/python3.13/site-packages/temporalio/worker/_workflow_instance.py:712> cb=[set.remove()]>()>
```

Ceci est li√© √† un [bug entre le debugger de PyCharm et AsyncIO](https://youtrack.jetbrains.com/issue/PY-64542),
pour le r√©gler :
* Help > Find Actions > Registry (+ Entrer)
* CTRL + F, chercher **python.debug.asyncio.repl**
* D√©cocher, relancer PyCharm

Vous pouvez ensuite lancer le workflow via les 2 run configuration suivantes :
* D√©marrage du worker avec la configuration **Main Worker**
* Trigger du workflow avec la configuration Trigger Workflow > Part 2 - Indexing pre-fetch pages

#### VS Code et debug

Sur VS Code lancer les configurations : 
* Worker : `[üêç] Main Worker`
* D√©clencher le workflow : `[üêç] Trigger - Part 2 - Indexing pages`.

## Indexons des pages pr√©-t√©l√©charg√©es

Le workflow pr√©c√©dent ne fait qu'afficher dans la console du worker la liste des sources fournies en entr√©e,
pour aller droit au but et voir du r√©sultat rapidement dans notre application nous allons coder
le stage d'indexation qui insert en base vectorielle le contenu brute (donc HTML) des 2 pages pr√©-t√©l√©charg√©s.

On aura ainsi le workflow suivant :
![](./images/workflow-pipeline-part2.excalidraw.png)

### Compl√©ter l'activit√© index_source_no_chunk_activity

Ouvrir le fichier [index_source_no_chunk_activity.py](../avelbot-ingestion-py/src/avelbot_ingestion/activities/index_source_no_chunk_activity.py).

L'objectif de cette activit√© est simple, basculer le contenu de la source avec laquelle est appel√©e en base vectorielle :
* Cr√©ation d'un Embedding Open AI, attention il faut bien utiliser le m√™me mod√®le que l'application AvelBot, en va r√©cup√©rer son nom depuis la configuration d'indexing pass√©e en entr√©e du workflow.
```python
embedding = OpenAIEmbeddings(model=stage_config.openai_embedding_model)
```
* Cr√©ation du VectorStore Postgres √©galement avec les informations de configuration d'entr√©e du workflow :
```python
vector_store = PGVector(
      connection=stage_config.database_uri,
      collection_name=stage_config.collection_name,
      embeddings=embedding,
  )
```
* Lire le contenu du fichier HTML pr√©-t√©l√©charg√© (via les Run Configuration PyCharm et VS Code le workder est ex√©cut√© avec comme dossier de context la racine de repo comme les paths indiqu√© dans les sources) :
```python
with open(file_path, "r", encoding="utf-8") as f:
      content = f.read()
```
* Cr√©ation d'un document avec le contenu et les bonnes m√©tadata attendue par AvelBot (title et source) :
```python
doc = Document(
        page_content=content,
        metadata={
            "source": source.uri,
            "title": source.metadata.get("title"),
        },
    )
```
* Ajout √† la base vectorielle :
```python
vector_store.add_documents([doc])
```

<details>
  <summary>Code complet de `index_source_no_chunk_activity.py`</summary>

```python
from temporalio import activity

from avelbot_ingestion.helpers.logging_config import get_app_logger
from avelbot_ingestion.models.IndexingStageConfiguration import IndexingStageConfiguration
from avelbot_ingestion.models.Source import Source

from langchain_postgres import PGVector
from langchain_openai import OpenAIEmbeddings
from langchain_core.documents import Document

logger = get_app_logger(__name__)

@activity.defn(name="PY-index_source_no_chunk_activity")
async def index_source_no_chunk_activity(source: Source, stage_config: IndexingStageConfiguration) -> Source:
    """
    Activit√©e d'indexation d'une source non chunk√©e en base vectorielle.

    :param source: Source non chunk√©e √† indexer en base vectorielle.
    """
    logger.info("Indexation de la source :", source.uri)

    # COMPLETER ICI - START
    # embedding = # Cr√©er l'embedding
    # vector_store = # Cr√©er le vector store
    # Lire le contenu de la page t√©l√©charg√©e pr√©sente √† source.raw_file_path
    # Cr√©er un Document (langchain) :
    # - avec le contenu comme page_content
    # - en metadata "source" qui vaut source.uri
    # En utilisant le vector_store ajouter le document cr√©√©.

    logger.debug("Creating OpenAI embedding using model : %s", stage_config.openai_embedding_model)
    embedding = OpenAIEmbeddings(model=stage_config.openai_embedding_model)
    vector_store = PGVector(
        connection=stage_config.database_uri,
        collection_name=stage_config.collection_name,
        embeddings=embedding,
    )

    with open(source.raw_file_path, "r", encoding="utf-8") as f:
        content = f.read()

    doc = Document(
        page_content=content,
        metadata={
            "source": source.uri,
            "title": source.metadata.get("title"),
        },
    )
    vector_store.add_documents([doc])
    # COMPLETER ICI - END

    return  source

```
</details>

### Appeler l'activit√©e depuis le workflow

Maintenant nous pouvez appeler cette activit√© depuis le workflow, ouvrez [ingestion_workflow.py](../avelbot-ingestion-py/src/avelbot_ingestion/workflows/ingestion_workflow.py)
et d√©commentez les lignes suivantes :
```python
# COMPLETER ICI / D√©commenter ici - START (partie 2)
# - D√©commenter les lignes suivantes
# - Compl√©ter l'activit√©e index_source_no_chunk_activity
indexing_tasks = [
    workflow.execute_activity(
        activity="PY-index_source_no_chunk_activity",
        task_queue="PY_WORKER_TASK_QUEUE",
        args=[source, ingestion_workflow_input.indexing_config], # Ne pas oublier de passer le param√®tre suppl√©mentaire ici
        start_to_close_timeout=timedelta(seconds=WORKFLOW_ACTIVITY_START_TO_CLOSE_TIMEOUT),
    )
    for source in sources
]
sources = await asyncio.gather(*indexing_tasks)  # Ex√©cute toutes les t√¢ches en parall√®le sur chaques sources
logger.info("Nombre de sources index√©s : %i", len(sources))
# COMPLETER ICI - END
```

### Indexons les pages

* Avant de relancer le workflow retourner sur AvelBot pour vider la base vectorielle.
* Relancez votre worker Main Worker pour que les changements soient bien pris en comptes.
* Puis relancer la worker (PyCharm: `Part 2 - Indexing workflow` - VSCode: `"[üêç] Trigger - Part 2 - Indexing pages"` ).

Vous devriez avoir ce r√©sultat dans Temporal :
![](./images/part2-full-workflow-temporal-webui.png)

### V√©rifions sur AvelBot

Retournez sur AvelBot pour v√©rifier que les documents sont bien en base :
![](./images/part2-base-vect-resultat.png)

Interroger le bot par exemple sur l'ascenseur urbain `Il y aura quoi au CHU ?` :
![](./images/part2-reponse-bot-CHU.png)

**üéâ Bravo vous avez fait votre premi√®re ingestion.**

> On remarque que le temps de r√©ponse est assez long ü§î, allez voir la trace langfuse par curiosit√©.
> Regardez bien le dernier appel √† OpenAI, son temps d'ex√©cution et le nombre de token.
![](./images/part2-langfuse-latency-openai-token-size.png)

C'est la cata ! comme on a ing√©r√© les pages brute le nombre de token explose et le temps d'exc√©ution aussi.

**Nous allons voir pour nettoyer les documents dans la partie suivante et garder uniquement le contenu utile**.

Aller √† la [Partie 3 : Clean les pages et les convertir en markdown (premi√®re activit√© TypeScript)](./part3-cleaning_pages_in_typescript.md)
