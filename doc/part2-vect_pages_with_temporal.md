# Part 2 - Vectorisons quelques pages avec Temporal IO

* ‚è∞ Dur√©e : 30min
* üéØ Objectifs :
  * D√©couvrir Temporal et son backoffice
  * D√©couverte du mod√®le de donn√©es utilis√© pendant le workshop
  * Coder et lancer l'activit√© d'indexation sur des pages web pr√©-t√©l√©charg√©es

## D√©couverte de Temporal IO

Temporal IO est une plateforme open-source de gestion de workflows distribu√©s, con√ßue pour rendre les syst√®mes complexes
fiables, r√©silients et faciles √† raisonner. Elle permet d‚Äôorchestrer des t√¢ches longues, critiques ou d√©pendantes les
unes des autres (paiements, traitements de donn√©es, automatisations m√©tiers, pipelines IA, etc.) tout en garantissant 
la reprise automatique en cas d‚Äôerreur, de crash, de d√©ploiement, ou m√™me de red√©marrage de machine. Avec Temporal, 
chaque √©tape d‚Äôun workflow est durablement enregistr√©e dans un ‚Äúhistory log‚Äù, ce qui √©limine la gestion manuelle des 
√©tats, des timeouts, des retry policies, du backoff, ou des verrous distribu√©s.

Concr√®tement, Temporal s√©pare la logique m√©tier (les workflows) et l‚Äôex√©cution des actions externes (les activities), 
tout en offrant des primitives puissantes : timers fiables, retours asynchrones, signaux, queries, sous-workflows, et 
une coh√©rence garantie. Cela permet d‚Äô√©crire du code simple, comme une fonction normale, qui devient automatiquement 
r√©sistant aux pannes et hautement scalable gr√¢ce au moteur de Temporal. C‚Äôest aujourd‚Äôhui utilis√© par des entreprises 
comme Datadog, OVH, Stripe, Snap ou Descript pour orchestrer des milliers √† des millions d‚Äôop√©rations de mani√®re s√ªre et 
d√©terministe.

### Pourquoi le choix de Temporal IO

Les activit√©s de collecte de donn√©es sont des activit√©s longues (un web crawling peut s‚Äô√©taler sur plusieurs heures),
pour d√©couvrir (crawling) et t√©l√©charger (scraping) des milliers de pages web.

Le nettoyage des documents collect√©s et leur conversion sont √©galement des t√¢ches longues, qui peuvent parfois n√©cessiter
des ressources GPU (mod√®les de d√©tection de layout, OCR‚Ä¶) et doivent pouvoir reprendre
sans tout rejouer.

Enfin, l‚Äôindexation / vectorisation des documents peut elle aussi, en fonction des mod√®les utilis√©s et des ressources
disponibles, s‚Äô√©taler sur plusieurs heures, voire des jours d‚Äôex√©cution.

### Mod√®le de donn√©es qui serait utilis√©

Dans ce workshop, nous allons travailler avec le mod√®le de donn√©es suivant, il est d√©j√† impl√©ment√© :
* En python au travers d'objets PyDantic disponible ICI TODO
* En Typescript (nous le verrons par la suite)

En bref :
* **Source** : repr√©sente chaque page web tout au long de son traitement
  - source.medata : contien des cl√© valeur qui arriveront en base vectorielle, notamment la metdata.title qui contien le titre de la page.
* **IngestionWorkflowInput** : repr√©sente les donn√©es d'entr√©e de notre workflow

```mermaid
---
title: Mod√®le de donn√©es - Workflow d'ingestion
---
classDiagram
    class Source{
        +String uri
        +MimeTypesEnum mime_type
        +StageEnum current_stage
        +String error
        +String raw_file_path
        +String converted_md_path
        +String chunking_file_path
        +Dict metadata
    }
    Source "1" --o "1" MimeTypesEnum : as format
    Source "1" --o "1" StageEnum : is at current state
    Source "1" --o "1" StatusEnum : as current status
    
    class StageEnum{
    <<enumeration>>
        CRAWLING
        SCRAPING
        CONVERTION
        CHUNKING
        INDEXING
    }
    
    class MimeTypesEnum{
        TEXT_HTML
        UNSUPORTED_MIME_TYPE
    }
    
    class StageConfiguration{
        +int bulk_size
    }
    
    class IndexingStageConfiguration{
        +String collection_name
        +String database_uri
        +String openai_embedding_model
    }
    
    class IngestionWorkflowInput{
        +List~Source~ sources
        +IndexingStageConfiguration indexing_config
    }
    IngestionWorkflowInput "1" --o "1" IndexingStageConfiguration: indexing_config
```

Ce mod√®le est d√©crit en json sch√©mas dans *ingestion-workflow-model-schemas*, nous utilisons du json sch√©ma pour 
le d√©cliner en Pydantic et en mod√®le TypeScript, puisque Temporal nous permet d'impl√©menter des activit√©s dans plusieurs
langages, nous verrons ceci en partie 4.

*Vous n'aurez pas √† toucher aux sch√©mas, si besoin vous avez des Run Config PyCharm / Intelij permettant de les re-g√©n√©rer
en python et typescript.*

### Notre premier workflow

On va commencer par aller droit au but de mani√®re tr√®s simple mettre en base le contenu brute des 2 pages d'article
pr√©-t√©l√©charg√©e pr√©sentes dans *ingestion-workflow-py/ressources/brest_transport_pre_scraped_pages/*.

Ouvrez le fichier *ingestion-workflow-py/src/ingestion_workflow/workflows/ingestion_workflow.py* :


